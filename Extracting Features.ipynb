{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wisdm import wisdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import time\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wisdm.set_data(version=\"2\", make_compatible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097 not in set\n",
      "1809 not in set\n",
      "1813 not in set\n",
      "1814 not in set\n"
     ]
    }
   ],
   "source": [
    "user_dfs = {}\n",
    "\n",
    "for user_id in wisdm.user_ids:\n",
    "    try:\n",
    "        user_df = pd.read_pickle('./datasets/WISDM_v2/temporary_user_dataframes/' + user_id + '_raw_segmented.pickle')\n",
    "        user_dfs[user_id] = user_df\n",
    "    except FileNotFoundError as fnfe:\n",
    "        print(\"%s not in set\" % user_id)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_df = user_dfs[wisdm.user_ids[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle NaN Values in Segment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/472179 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"%s/%s missing values\" % (np.sum(np.isnan(user_df['segment_id'])), len(user_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_df['segment_id'] = user_df['segment_id'].fillna(method=\"bfill\", limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/472179 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"%s/%s missing values\" % (np.sum(np.isnan(user_df['segment_id'])), len(user_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other NaN Values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo : Check for all users, The first user seems fine for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_0 = user_df[user_df['segment_id'] == 0]\n",
    "len(segment_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-inf, -2.5, 0.0, 2.5, 5.0, 7.5, 10.0, 12.5, 15.0, 17.5, inf]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_ranges = list(np.arange(-2.5, 20, 2.5))\n",
    "bin_ranges = [-np.inf] + bin_ranges\n",
    "bin_ranges = bin_ranges + [np.inf]\n",
    "bin_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 140,  46,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts, _ = np.histogram(segment_0['x-acc'], bins=bin_ranges, density=False)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_bins(segment_df):\n",
    "    counts_x, _ = np.histogram(segment_df['x-acc'], bins=bin_ranges, density=False)\n",
    "    counts_y, _ = np.histogram(segment_df['y-acc'], bins=bin_ranges, density=False)\n",
    "    counts_z, _ = np.histogram(segment_df['z-acc'], bins=bin_ranges, density=False)\n",
    "    return counts_x, counts_y, counts_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.7780745029449463 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "user_segments = user_df['segment_id'].unique()\n",
    "\n",
    "bin_rows = []\n",
    "for segment in user_segments:\n",
    "    segment_df = user_df[user_df['segment_id'] == segment]\n",
    "    bins = fill_bins(segment_df)\n",
    "    bin_rows.append(bin_rows)\n",
    "\n",
    "finish = time.time()\n",
    "print(\"Took %s seconds\" % (finish - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get XAVG, YAVG, ZAVG\n",
    "the average x, y, and z values over the 200 records in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_avg(segment_df):\n",
    "    xavg = segment_df['x-acc'].mean()\n",
    "    yavg = segment_df['y-acc'].mean()\n",
    "    zavg = segment_df['z-acc'].mean()\n",
    "    return xavg, yavg, zavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.592491388320923 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "user_segments = user_df['segment_id'].unique()\n",
    "\n",
    "f_rows = []\n",
    "for segment in user_segments:\n",
    "    segment_df = user_df[user_df['segment_id'] == segment]\n",
    "    f = get_avg(segment_df)\n",
    "    f_rows.append(f)\n",
    "\n",
    "finish = time.time()\n",
    "print(\"Took %s seconds\" % (finish - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get XPEAK, YPEAK, ZPEAK\n",
    "approximations of the dominant\n",
    "frequency. First, the greatest value in the series is\n",
    "identified, then all local peak values within 10% of\n",
    "its amplitude are identified. If the number of peaks\n",
    "is less than 3, then the threshhold is lowered until\n",
    "at least 3 peaks can be found. The times between\n",
    "consecutive peaks are summed and divided by the number\n",
    "of peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_peak_times(segment_df):\n",
    "    axes = ['x-acc', 'y-acc', 'z-acc']\n",
    "    \n",
    "    peak_feature_values = {axis : None for axis in axes}\n",
    "    for axis in axes:\n",
    "        sorted_indeces = segment_df[axis].argsort()\n",
    "        max_peak = segment_df[axis].iloc[sorted_indeces.iloc[-1]]\n",
    "        threshold = max_peak * 0.9\n",
    "        peaks_df = segment_df[segment_df[axis] > threshold]\n",
    "        if len(peaks_df) < 3:\n",
    "            peaks_df = segment_df.iloc[sorted_indeces.iloc[-3:]]\n",
    "        \n",
    "        peaks_df.sort_values('timestamp', ascending=False, inplace=True)\n",
    "\n",
    "        peak_diffs = []\n",
    "        #print(len(peaks_df))\n",
    "        iter_peaks = peaks_df['timestamp'].iteritems()\n",
    "        _, last_ts = next(iter_peaks)\n",
    "\n",
    "        for _, pt in peaks_df['timestamp'].iteritems():\n",
    "            peak_diffs.append(pt.timestamp() - last_ts.timestamp())\n",
    "            last_ts = pt\n",
    "        peak_feature_values[axis] = np.mean(peak_diffs)\n",
    "\n",
    "    return peak_feature_values['x-acc'], peak_feature_values['y-acc'], peak_feature_values['z-acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 133.62716960906982 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "user_segments = user_df['segment_id'].unique()\n",
    "\n",
    "f_rows = []\n",
    "for segment in user_segments:\n",
    "    segment_df = user_df[user_df['segment_id'] == segment]\n",
    "    f = get_peak_times(segment_df)\n",
    "    f_rows.append(f)\n",
    "\n",
    "finish = time.time()\n",
    "print(\"Took %s seconds\" % (finish - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XABSOLDEV, YABSOLDEV, ZABSOLDEV\n",
    "the average absolute deviations from the mean value for each axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_absdev(segment_df):\n",
    "    x_mean = segment_df['x-acc'].mean()\n",
    "    y_mean = segment_df['y-acc'].mean()\n",
    "    z_mean = segment_df['z-acc'].mean()\n",
    "    \n",
    "    x_absdev = np.mean([np.absolute(x_mean - x) for x in segment_df['x-acc']])\n",
    "    y_absdev = np.mean([np.absolute(y_mean - y) for y in segment_df['y-acc']])\n",
    "    z_absdev = np.mean([np.absolute(z_mean - z) for z in segment_df['z-acc']])\n",
    "    \n",
    "    return x_absdev, y_absdev, z_absdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 5.244106769561768 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "user_segments = user_df['segment_id'].unique()\n",
    "\n",
    "f_rows = []\n",
    "for segment in user_segments:\n",
    "    segment_df = user_df[user_df['segment_id'] == segment]\n",
    "    f = get_absdev(segment_df)\n",
    "    f_rows.append(f)\n",
    "\n",
    "finish = time.time()\n",
    "print(\"Took %s seconds\" % (finish - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XSTANDDEV, YSTANDDEV, ZSTANDDEV \n",
    "the standard deviations for each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sd(segment_df):\n",
    "    x_std = segment_df['x-acc'].std()\n",
    "    y_std = segment_df['y-acc'].std()\n",
    "    z_std = segment_df['z-acc'].std()\n",
    "    \n",
    "    return x_std, y_std, z_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTANT \n",
    "average of the square roots of the sum of the values\n",
    "   of each axis squared �(xi^2 + yi^2 + zi^2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_resultant(segment_df):\n",
    "    values = []\n",
    "    \n",
    "    for ind, row in segment_df.iterrows():\n",
    "        sum_val = (row['x-acc']**2) + (row['y-acc'] ** 2) + (row['z-acc'] ** 2)\n",
    "        values.append(sum_val)\n",
    "    return np.mean(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 49.957321882247925 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "user_segments = user_df['segment_id'].unique()\n",
    "\n",
    "f_rows = []\n",
    "for segment in user_segments:\n",
    "    segment_df = user_df[user_df['segment_id'] == segment]\n",
    "    f = get_resultant(segment_df)\n",
    "    f_rows.append(f)\n",
    "\n",
    "finish = time.time()\n",
    "print(\"Took %s seconds\" % (finish - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9',\n",
    "                 'Y0', 'Y1', 'Y2', 'Y3', 'Y4', 'Y5', 'Y6', 'Y7', 'Y8', 'Y9',\n",
    "                 'Z0', 'Z1', 'Z2', 'Z3', 'Z4', 'Z5', 'Z6', 'Z7', 'Z8', 'Z9',\n",
    "                 'XAVG', 'YAVG', 'ZAVG',\n",
    "                 'XPEAK', 'YPEAK', 'ZPEAK',\n",
    "                 'XABSOLDEV', 'YABSOLDEV', 'ZABSOLDEV',\n",
    "                 'XSTANDDEV', 'YSTANDDEV', 'ZSTANDDEV',\n",
    "                 'RESULTANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bins_df(x_bin_list, y_bin_list, z_bin_list):\n",
    "    rows = []\n",
    "    \n",
    "    for bin_sets in zip(x_bin_list, y_bin_list, z_bin_list):\n",
    "        row = np.hstack(bin_sets)\n",
    "        rows.append(row)\n",
    "    bins_df = pd.DataFrame(rows, columns=feature_names[:30])\n",
    "    return bins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timestamp(segment_df):\n",
    "    return segment_df['timestamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_user_df(user_df):\n",
    "    ts = user_df['timestamp'].unique()\n",
    "    print(\"%s timestamps\" % len(ts))\n",
    "    rows = []\n",
    "    for ind, t in enumerate(ts):\n",
    "        #if (ind % 1000) == 0:\n",
    "            #print(\"At %s\" % ind)\n",
    "        ts_df = user_df[user_df['timestamp'] == ts[0]]\n",
    "        class_labels = ts_df['class'].unique()\n",
    "        \n",
    "        ts_df = ts_df[ts_df['class'] != 'NoLabel']\n",
    "        ts_df.reset_index(drop=True, inplace=True)\n",
    "        ts_df = ts_df.drop(ts_df.index[1:]) # maybe we should keep which ever one has a label?\n",
    "        rows.append(ts_df)\n",
    "    user_df = pd.concat(rows)\n",
    "    return user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(user_df):\n",
    "    start = time.time()\n",
    "    user_id = user_df['user'].unique()[0]\n",
    "    segments = user_df['segment_id'].unique()\n",
    "    timestamps = []\n",
    "    class_labels = []\n",
    "    \n",
    "    x_bin_list = []\n",
    "    y_bin_list = []\n",
    "    z_bin_list = []\n",
    "\n",
    "    x_avg_list = []\n",
    "    y_avg_list = []\n",
    "    z_avg_list = []\n",
    "\n",
    "    x_peak_list = []\n",
    "    y_peak_list = []\n",
    "    z_peak_list = []\n",
    "\n",
    "    x_absdev_list = []\n",
    "    y_absdev_list = []\n",
    "    z_absdev_list = []\n",
    "\n",
    "    x_sd_list = []\n",
    "    y_sd_list = []\n",
    "    z_sd_list = []\n",
    "\n",
    "    resultant_list = []\n",
    "\n",
    "    for segment in segments:\n",
    "        segment_df = user_df[user_df['segment_id'] == segment]\n",
    "        class_label = str(stats.mode(list(segment_df['class']))[0][0])\n",
    "        timestamp = get_timestamp(segment_df)\n",
    "        x_bins, y_bins, z_bins = fill_bins(segment_df)\n",
    "        x_avg, y_avg, z_avg = get_avg(segment_df)\n",
    "        x_peak, y_peak, z_peak = get_peak_times(segment_df)\n",
    "        x_absdev, y_absdev, z_absdev = get_absdev(segment_df)\n",
    "        x_sd, y_sd, z_sd = get_sd(segment_df)\n",
    "        resultant = get_resultant(segment_df)\n",
    "        \n",
    "        class_labels.append(class_label)\n",
    "        timestamps.append(timestamp)\n",
    "        \n",
    "        x_bin_list.append(x_bins)\n",
    "        y_bin_list.append(y_bins)\n",
    "        z_bin_list.append(z_bins)\n",
    "\n",
    "        x_avg_list.append(x_avg)\n",
    "        y_avg_list.append(y_avg)\n",
    "        z_avg_list.append(z_avg)\n",
    "\n",
    "        x_peak_list.append(x_peak)\n",
    "        y_peak_list.append(y_peak)\n",
    "        z_peak_list.append(z_peak)\n",
    "\n",
    "        x_absdev_list.append(x_absdev)\n",
    "        y_absdev_list.append(y_absdev)\n",
    "        z_absdev_list.append(z_absdev)\n",
    "\n",
    "        x_sd_list.append(x_sd)\n",
    "        y_sd_list.append(y_sd)\n",
    "        z_sd_list.append(z_sd)\n",
    "        \n",
    "        resultant_list.append(resultant)\n",
    "    \n",
    "    f_df = make_bins_df(x_bin_list, y_bin_list, z_bin_list)\n",
    "    f_df['XAVG'] = x_avg_list\n",
    "    f_df['YAVG'] = y_avg_list\n",
    "    f_df['ZAVG'] = z_avg_list\n",
    "\n",
    "    f_df['XPEAK'] = x_peak_list\n",
    "    f_df['YPEAK'] = y_peak_list\n",
    "    f_df['ZPEAK'] = z_peak_list\n",
    "\n",
    "    f_df['XABSOLDEV'] = x_absdev_list\n",
    "    f_df['YABSOLDEV'] = x_absdev_list\n",
    "    f_df['ZABSOLDEV'] = y_absdev_list\n",
    "\n",
    "    f_df['XSTANDDEV'] = x_sd_list\n",
    "    f_df['YSTANDDEV'] = x_sd_list\n",
    "    f_df['ZSTANDDEV'] = y_sd_list\n",
    "\n",
    "    f_df['RESULTANT'] = resultant_list\n",
    "    f_df['user_id'] = [user_id] * len(segments)\n",
    "    f_df['segment_id'] = segments\n",
    "    f_df['timestamps'] = timestamps\n",
    "    f_df['class'] = class_labels\n",
    "    return f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355248 timestamps\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'finish_cleaning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-50d4c6a80b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muser_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_user_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfinished_cleaning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Took %s to finish cleaning\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinish_cleaning\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfeatures_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'finish_cleaning' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "user_df = clean_user_df(user_df)\n",
    "finished_cleaning = time.time()\n",
    "print(\"Took %s to finish cleaning\" % (finished_cleaning - start))\n",
    "features_df = get_features(user_df)\n",
    "finish = time.time()\n",
    "\n",
    "print(\"Took %s seconds\" % (finish - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1203.8877215385437 to finish cleaning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/scipy/stats/stats.py:253: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1249.0434832572937 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "finished_cleaning = time.time()\n",
    "print(\"Took %s to finish cleaning\" % (finished_cleaning - start))\n",
    "features_df = get_features(user_df)\n",
    "finish = time.time()\n",
    "\n",
    "print(\"Took %s seconds\" % (finish - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Standing'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "* Fix clean_user_df() so that it keeps the NoLabel frames that have ONLY NoLabel\n",
    "* Test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
