{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, ShuffleSplit\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss, accuracy_score, precision_recall_curve, average_precision_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wisdm import wisdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import time\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_trees = 10000\n",
    "n_cores = 30\n",
    "oob_score = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_rows(features, labels):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    return features[permutation], labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impersonal_pred(model, test_features):\n",
    "    scaled_test_features = impersonal_scaler.transform(test_features)\n",
    "    \n",
    "    impersonal_predictions = model.predict(scaled_test_features)\n",
    "    impersonal_probabilities = model.predict_proba(scaled_test_features)\n",
    "    return impersonal_predictions, impersonal_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def personal_pred(personal_features, personal_labels, test_features):\n",
    "    # build personal model and predict\n",
    "    personal_scaler = StandardScaler().fit(personal_features)\n",
    "    scaled_personal_features = personal_scaler.transform(personal_features)\n",
    "    scaled_test_features = personal_scaler.transform(test_features)\n",
    "\n",
    "    personal_clf = wisdm.weka_RF()\n",
    "    personal_clf.set_params(n_estimators=n_trees, n_jobs=n_cores)\n",
    "    personal_clf.fit(scaled_personal_features, personal_labels)\n",
    "    \n",
    "    personal_predictions = personal_clf.predict(scaled_test_features)\n",
    "    personal_probabilities = personal_clf.predict_proba(scaled_test_features)\n",
    "    return personal_predictions, personal_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hybrid_pred(impersonal_features, impersonal_labels, \\\n",
    "                personal_features, personal_labels, \\\n",
    "                test_features, number_of_samples = None, \\\n",
    "                probabilities=None, \\\n",
    "                sampling_function=None):\n",
    "    if sampling_function == None:\n",
    "        hybrid_labels = np.hstack((personal_labels, impersonal_labels))\n",
    "        hybrid_features = np.vstack((personal_features, impersonal_features))\n",
    "        hybrid_features, hybrid_labels = shuffle_rows(hybrid_features, hybrid_labels)\n",
    "    else:\n",
    "        hybrid_features, hybrid_labels = sampling_function(personal_features, personal_labels, probabilities, number=number_of_samples)\n",
    "    \n",
    "    hybrid_scaler = StandardScaler().fit(hybrid_features)\n",
    "    scaled_hybrid_features = hybrid_scaler.transform(hybrid_features)\n",
    "    scaled_test_features = hybrid_scaler.transform(test_features)\n",
    "\n",
    "    hybrid_clf = wisdm.weka_RF()\n",
    "    hybrid_clf.set_params(n_estimators=n_trees, n_jobs=n_cores)\n",
    "    hybrid_clf.fit(scaled_hybrid_features, hybrid_labels)\n",
    "    \n",
    "    hybrid_predictions = hybrid_clf.predict(scaled_test_features)\n",
    "    hybrid_probabilities = hybrid_clf.predict\n",
    "    \n",
    "    return hybrid_predictions, hybrid_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confidence_sample(features, labels, probabilities, number=None, top=False):\n",
    "    confidence_ranking = np.argsort(np.max(probabilities, axis=1))\n",
    "    \n",
    "    if not number:\n",
    "        return features[confidence_ranking], labels[confidence_ranking]\n",
    "    \n",
    "    if top:\n",
    "        return features[confidence_ranking[-number:]], labels[confidence_ranking[-number:]]\n",
    "    return features[confidence_ranking[:number]], labels[confidence_ranking[:number]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Finished Training in 23.91435718536377 seconds\n",
      "predicting...\n",
      "User : 194\n",
      "\t impersonal acc : 0.767\n",
      "\t personal acc : 0.733\n",
      "\t hybrid acc : 0.667\n",
      "\n",
      "\t impersonal acc : 0.733\n",
      "\t personal acc : 0.800\n",
      "\t hybrid acc : 0.833\n",
      "\n",
      "\t impersonal acc : 0.767\n",
      "\t personal acc : 0.900\n",
      "\t hybrid acc : 0.900\n",
      "\n",
      "\t impersonal acc : 0.800\n",
      "\t personal acc : 0.833\n",
      "\t hybrid acc : 0.833\n",
      "\n",
      "User : 998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-551d09484c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# build personal model and predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mpersonal_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersonal_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_personal_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_personal_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mpersonal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersonal_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mpersonal_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersonal_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0a48dc1cd573>\u001b[0m in \u001b[0;36mpersonal_pred\u001b[0;34m(personal_features, personal_labels, test_features)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpersonal_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwisdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweka_RF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpersonal_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpersonal_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_personal_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersonal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpersonal_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersonal_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_test_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 315\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    316\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0m_set_random_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mto_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random_state'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__random_state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mto_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_RAND_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m    226\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0;31m# We need deprecation warnings to always be on in order to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;31m# catch deprecated param values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0m\u001b[1;32m    200\u001b[0m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0m\u001b[1;32m    200\u001b[0m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#experiment setup\n",
    "number_of_personal_samples = 10\n",
    "test_size = 30\n",
    "\n",
    "wisdm.set_data(version=\"1\", make_compatible=True)\n",
    "impersonal_df = wisdm.remove_all_nan(wisdm.data_df)\n",
    "impersonal_labels = np.array([t.decode(\"utf-8\") for t in impersonal_df['class'].as_matrix()])\n",
    "impersonal_features = impersonal_df.as_matrix(columns=[impersonal_df.columns[1:-1]])\n",
    "impersonal_scaler = StandardScaler().fit(impersonal_features)\n",
    "scaled_train_X = impersonal_scaler.transform(impersonal_features)\n",
    "impersonal_clf = wisdm.weka_RF()\n",
    "impersonal_clf.set_params(n_estimators=n_trees, n_jobs=n_cores)\n",
    "\n",
    "start=time.time()\n",
    "print(\"Training...\")\n",
    "impersonal_clf.fit(scaled_train_X, impersonal_labels)\n",
    "finished_training = time.time()\n",
    "print(\"Finished Training in %s seconds\" % (finished_training - start))\n",
    "wisdm.set_data(version=\"2\", make_compatible=True)\n",
    "result_rows = []\n",
    "\n",
    "number_of_personal_samples = 10\n",
    "ignored_users = []\n",
    "print(\"predicting...\")\n",
    "for user_id in wisdm.user_ids:\n",
    "    print(\"User : %s\" % user_id)\n",
    "    user_df = wisdm.data_df[wisdm.data_df['user'] == user_id]\n",
    "    \n",
    "    if len(user_df) < 40:\n",
    "        print(\"Not Enough Data, skipping...\")\n",
    "        ignored_users.append(user_id)\n",
    "        continue\n",
    "    \n",
    "    personal_labels = np.array([t.decode(\"utf-8\") for t in user_df['class'].as_matrix()])\n",
    "    personal_features = user_df.as_matrix(columns=[user_df.columns[1:-1]])\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=4, test_size=test_size, train_size = number_of_personal_samples)\n",
    "    \n",
    "    personal_scores = []\n",
    "    impersonal_scores = []\n",
    "    hybrid_scores = []\n",
    "    \n",
    "    shuffle_count = 0\n",
    "    try:\n",
    "        for train_index, test_index in sss.split(personal_features, personal_labels):\n",
    "            # data for personal model\n",
    "            random_personal_features = personal_features[train_index]\n",
    "            random_personal_labels = personal_labels[train_index]\n",
    "\n",
    "            # create an active pool of everything not in the test set for active learning / hybrid model\n",
    "            active_pool_mask = np.ones(personal_labels.shape, dtype=bool)\n",
    "            active_pool_mask[test_index] = False\n",
    "            active_pool_features = personal_features[active_pool_mask]\n",
    "            active_pool_labels = personal_labels[active_pool_mask]\n",
    "\n",
    "            # test set\n",
    "            test_features = personal_features[test_index]\n",
    "            test_labels = personal_labels[test_index]\n",
    "\n",
    "            # build personal model and predict\n",
    "            personal_predictions, _ = personal_pred(random_personal_features, random_personal_labels, test_features)\n",
    "            personal_score = accuracy_score(test_labels, personal_predictions)\n",
    "            personal_scores.append(personal_score)\n",
    "\n",
    "            # build impersonal model and predict\n",
    "            impersonal_predictions, _ = impersonal_pred(impersonal_clf, test_features)\n",
    "            impersonal_score = accuracy_score(test_labels, impersonal_predictions)\n",
    "            impersonal_scores.append(impersonal_score)\n",
    "\n",
    "            # build hybrid model and predict\n",
    "            impersonal_probabilities = impersonal_clf.predict_proba(active_pool_features)\n",
    "            hybrid_predictions, _ = hybrid_pred(impersonal_features, impersonal_labels, \\\n",
    "                                                random_personal_features, random_personal_labels, \\\n",
    "                                                test_features)\n",
    "\n",
    "            hybrid_score = accuracy_score(test_labels, hybrid_predictions)\n",
    "            hybrid_scores.append(hybrid_score)\n",
    "            print(\"\\t impersonal acc : %.3f\" % impersonal_score)\n",
    "            print(\"\\t personal acc : %.3f\" % personal_score)\n",
    "            print(\"\\t hybrid acc : %.3f\" % hybrid_score)\n",
    "            print(\"\")\n",
    "\n",
    "            result_row = {\"user_id\" : user_id,\n",
    "                          \"shuffle\" : shuffle_count,\n",
    "                          \"impersonal\" : impersonal_score,\n",
    "                          \"personal\" : personal_score,\n",
    "                          \"hybrid\" : hybrid_score}\n",
    "            result_rows.append(result_row)\n",
    "            shuffle_count += 1\n",
    "    except ValueError as ve:\n",
    "        if \"The least populated class\" in ve.args[0]:\n",
    "            print(\"\\tNot enough labeled data for %s\" % user_id)\n",
    "            ignored_users.append(user_id)\n",
    "            continue\n",
    "        else:\n",
    "            raise ve\n",
    "\n",
    "finished_predicting = time.time()\n",
    "print(\"Finished predicting in %s seconds\" % (finished_predicting - finished_training))\n",
    "print(\"Users without enough data : %s\" % ignored_users)\n",
    "\n",
    "results_df_exp1_10 = pd.DataFrame(result_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df_exp1_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df_exp1_10.to_pickle(\"exp1_results_10samples.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df_exp1_30.to_pickle(\"exp1_results_30samples.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df_exp1_10.to_pickle(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Impersonal Accuracies M=%.3f, SD=%.3f\" % (results_df_exp1_10['impersonal'].mean(), results_df_exp1_10['impersonal'].std()))\n",
    "print(\"Personal Accuracies M=%.3f, SD=%.3f\" % (results_df_exp1_10['personal'].mean(), results_df_exp1_10['personal'].std()))\n",
    "print(\"Hybrid Accuracies M=%.3f, SD=%.3f\" % (results_df_exp1_10['hybrid'].mean(), results_df_exp1_10['hybrid'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_impersonal = []\n",
    "mean_personal = []\n",
    "mean_hybrid = []\n",
    "\n",
    "for user_id in results_df_exp1_10['user_id'].unique():\n",
    "    user_df = results_df_exp1_10[results_df_exp1_10['user_id']==user_id]\n",
    "    mean_impersonal.append(user_df['impersonal'].mean())\n",
    "    mean_personal.append(user_df['personal'].mean())\n",
    "    mean_hybrid.append(user_df['hybrid'].mean())\n",
    "\n",
    "trace0 = go.Box(\n",
    "    y=mean_impersonal,\n",
    "    name='Impersonal',\n",
    "    marker=dict(\n",
    "        color='red',\n",
    "    ),\n",
    "    boxpoints='all',\n",
    "    jitter=0.3,\n",
    "    pointpos=-0.5\n",
    ")\n",
    "\n",
    "trace1 = go.Box(\n",
    "    y=mean_personal,\n",
    "    name='Personal (10 Samples)',\n",
    "    marker=dict(\n",
    "        color='blue',\n",
    "    ),\n",
    "    boxpoints='all',\n",
    "    jitter=0.1,\n",
    "    pointpos=-0.5\n",
    ")\n",
    "\n",
    "trace2 = go.Box(\n",
    "    y=mean_hybrid,\n",
    "    name='Hybrid (10 Samples)',\n",
    "    marker=dict(\n",
    "        color='green',\n",
    "    ),\n",
    "    boxpoints='all',\n",
    "    jitter=0.1,\n",
    "    pointpos=-0.5\n",
    ")\n",
    "data = [trace0, trace1, trace2]\n",
    "layout = go.Layout(yaxis=dict(title=\"Accuracy\"), showlegend=False)\n",
    "fig=go.Figure(data=data,layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 with 30 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#experiment setup\n",
    "number_of_personal_samples = 10\n",
    "test_size = 30\n",
    "\n",
    "wisdm.set_data(version=\"1\", make_compatible=True)\n",
    "impersonal_df = wisdm.remove_all_nan(wisdm.data_df)\n",
    "impersonal_labels = np.array([t.decode(\"utf-8\") for t in impersonal_df['class'].as_matrix()])\n",
    "impersonal_features = impersonal_df.as_matrix(columns=[impersonal_df.columns[1:-1]])\n",
    "impersonal_scaler = StandardScaler().fit(impersonal_features)\n",
    "scaled_train_X = impersonal_scaler.transform(impersonal_features)\n",
    "impersonal_clf = wisdm.weka_RF()\n",
    "impersonal_clf.set_params(n_estimators=n_trees, n_jobs=n_cores)\n",
    "\n",
    "start=time.time()\n",
    "print(\"Training...\")\n",
    "impersonal_clf.fit(scaled_train_X, impersonal_labels)\n",
    "finished_training = time.time()\n",
    "print(\"Finished Training in %s seconds\" % (finished_training - start))\n",
    "wisdm.set_data(version=\"2\", make_compatible=True)\n",
    "result_rows = []\n",
    "\n",
    "number_of_personal_samples = 10\n",
    "ignored_users = []\n",
    "print(\"predicting...\")\n",
    "for user_id in wisdm.user_ids:\n",
    "    print(\"User : %s\" % user_id)\n",
    "    user_df = wisdm.data_df[wisdm.data_df['user'] == user_id]\n",
    "    \n",
    "    if len(user_df) < 40:\n",
    "        print(\"Not Enough Data, skipping...\")\n",
    "        ignored_users.append(user_id)\n",
    "        continue\n",
    "    \n",
    "    personal_labels = np.array([t.decode(\"utf-8\") for t in user_df['class'].as_matrix()])\n",
    "    personal_features = user_df.as_matrix(columns=[user_df.columns[1:-1]])\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=4, test_size=test_size, train_size = number_of_personal_samples)\n",
    "    \n",
    "    personal_scores = []\n",
    "    impersonal_scores = []\n",
    "    hybrid_scores = []\n",
    "    \n",
    "    shuffle_count = 0\n",
    "    try:\n",
    "        for train_index, test_index in sss.split(personal_features, personal_labels):\n",
    "            # data for personal model\n",
    "            random_personal_features = personal_features[train_index]\n",
    "            random_personal_labels = personal_labels[train_index]\n",
    "\n",
    "            # create an active pool of everything not in the test set for active learning / hybrid model\n",
    "            active_pool_mask = np.ones(personal_labels.shape, dtype=bool)\n",
    "            active_pool_mask[test_index] = False\n",
    "            active_pool_features = personal_features[active_pool_mask]\n",
    "            active_pool_labels = personal_labels[active_pool_mask]\n",
    "\n",
    "            # test set\n",
    "            test_features = personal_features[test_index]\n",
    "            test_labels = personal_labels[test_index]\n",
    "\n",
    "            # build personal model and predict\n",
    "            personal_predictions, _ = personal_pred(random_personal_features, random_personal_labels, test_features)\n",
    "            personal_score = accuracy_score(test_labels, personal_predictions)\n",
    "            personal_scores.append(personal_score)\n",
    "\n",
    "            # build impersonal model and predict\n",
    "            impersonal_predictions, _ = impersonal_pred(impersonal_clf, test_features)\n",
    "            impersonal_score = accuracy_score(test_labels, impersonal_predictions)\n",
    "            impersonal_scores.append(impersonal_score)\n",
    "\n",
    "            # build hybrid model and predict\n",
    "            impersonal_probabilities = impersonal_clf.predict_proba(active_pool_features)\n",
    "            hybrid_predictions, _ = hybrid_pred(impersonal_features, impersonal_labels, \\\n",
    "                                                random_personal_features, random_personal_labels, \\\n",
    "                                                test_features)\n",
    "\n",
    "            hybrid_score = accuracy_score(test_labels, hybrid_predictions)\n",
    "            hybrid_scores.append(hybrid_score)\n",
    "            print(\"\\t impersonal acc : %.3f\" % impersonal_score)\n",
    "            print(\"\\t personal acc : %.3f\" % personal_score)\n",
    "            print(\"\\t hybrid acc : %.3f\" % hybrid_score)\n",
    "            print(\"\")\n",
    "\n",
    "            result_row = {\"user_id\" : user_id,\n",
    "                          \"shuffle\" : shuffle_count,\n",
    "                          \"impersonal\" : impersonal_score,\n",
    "                          \"personal\" : personal_score,\n",
    "                          \"hybrid\" : hybrid_score}\n",
    "            result_rows.append(result_row)\n",
    "            shuffle_count += 1\n",
    "    except ValueError as ve:\n",
    "        if \"The least populated class\" in ve.args[0]:\n",
    "            print(\"\\tNot enough labeled data for %s\" % user_id)\n",
    "            ignored_users.append(user_id)\n",
    "            continue\n",
    "        else:\n",
    "            raise ve\n",
    "\n",
    "finished_predicting = time.time()\n",
    "print(\"Finished predicting in %s seconds\" % (finished_predicting - finished_training))\n",
    "print(\"Users without enough data : %s\" % ignored_users)\n",
    "\n",
    "results_df_exp1_30 = pd.DataFrame(result_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_impersonal = []\n",
    "mean_personal = []\n",
    "mean_hybrid = []\n",
    "\n",
    "for user_id in results_df_exp1_30['user_id'].unique():\n",
    "    user_df = results_df_exp1_30[results_df_exp1_30['user_id']==user_id]\n",
    "    mean_impersonal.append(user_df['impersonal'].mean())\n",
    "    mean_personal.append(user_df['personal'].mean())\n",
    "    mean_hybrid.append(user_df['hybrid'].mean())\n",
    "\n",
    "trace0 = go.Box(\n",
    "    y=mean_impersonal,\n",
    "    name='Impersonal',\n",
    "    marker=dict(\n",
    "        color='red',\n",
    "    ),\n",
    "    boxpoints='all',\n",
    "    jitter=0.3,\n",
    "    pointpos=-0.5\n",
    ")\n",
    "\n",
    "trace1 = go.Box(\n",
    "    y=mean_personal,\n",
    "    name='Personal (30 Samples)',\n",
    "    marker=dict(\n",
    "        color='blue',\n",
    "    ),\n",
    "    boxpoints='all',\n",
    "    jitter=0.1,\n",
    "    pointpos=-0.5\n",
    ")\n",
    "\n",
    "trace2 = go.Box(\n",
    "    y=mean_hybrid,\n",
    "    name='Hybrid (30 Samples)',\n",
    "    marker=dict(\n",
    "        color='green',\n",
    "    ),\n",
    "    boxpoints='all',\n",
    "    jitter=0.1,\n",
    "    pointpos=-0.5\n",
    ")\n",
    "data = [trace0, trace1, trace2]\n",
    "layout = go.Layout(yaxis=dict(title=\"Accuracy\"), showlegend=False)\n",
    "fig=go.Figure(data=data,layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace1 = go.Bar(\n",
    "    x=['10 samples', '30 samples'],\n",
    "    y=[len(personal_is_best_10), len(personal_is_best_30)],\n",
    "    marker=dict(color=\"blue\"),\n",
    "    name='Personal Data'\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=['10 samples', '30 samples'],\n",
    "    y=[len(hybrid_is_best_10), len(hybrid_is_best_30)],\n",
    "    marker=dict(color=\"green\"),\n",
    "    name='Hybrid Data'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    xaxis=dict(title=\"# of personal samples\"),\n",
    "    yaxis=dict(title=\"# of users\")\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='stacked-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Finished Training in 23.827834367752075 seconds\n",
      "predicting...\n",
      "User : 194\n",
      "User : 998\n",
      "User : 1097\n",
      "Not Enough Data, skipping...\n",
      "User : 1104\n",
      "User : 1117\n",
      "User : 1205\n",
      "Not Enough Data, skipping...\n",
      "User : 1238\n",
      "User : 1246\n",
      "User : 1247\n",
      "Not Enough Data, skipping...\n",
      "User : 1253\n",
      "User : 1269\n",
      "Not Enough Data, skipping...\n",
      "User : 1274\n",
      "User : 1276\n",
      "Not Enough Data, skipping...\n",
      "User : 1277\n",
      "Not Enough Data, skipping...\n",
      "User : 1280\n",
      "Not Enough Data, skipping...\n",
      "User : 1319\n",
      "User : 1320\n",
      "User : 1477\n",
      "User : 1480\n",
      "Not Enough Data, skipping...\n",
      "User : 1491\n",
      "Not Enough Data, skipping...\n",
      "User : 1511\n",
      "Not Enough Data, skipping...\n",
      "User : 1512\n",
      "User : 1518\n",
      "Not Enough Data, skipping...\n",
      "User : 1531\n",
      "Not Enough Data, skipping...\n",
      "User : 1554\n",
      "Not Enough Data, skipping...\n",
      "User : 1559\n",
      "User : 1603\n",
      "User : 1676\n",
      "User : 1679\n",
      "Not Enough Data, skipping...\n",
      "User : 1683\n",
      "Not Enough Data, skipping...\n",
      "User : 1696\n",
      "Not Enough Data, skipping...\n",
      "User : 1703\n",
      "User : 1707\n",
      "User : 1723\n",
      "Not Enough Data, skipping...\n",
      "User : 1724\n",
      "Not Enough Data, skipping...\n",
      "User : 1726\n",
      "Not Enough Data, skipping...\n",
      "User : 1742\n",
      "User : 1745\n",
      "Not Enough Data, skipping...\n",
      "User : 1750\n",
      "Not Enough Data, skipping...\n",
      "User : 1757\n",
      "Not Enough Data, skipping...\n",
      "User : 1758\n",
      "User : 1759\n",
      "User : 1761\n",
      "Not Enough Data, skipping...\n",
      "User : 1763\n",
      "Not Enough Data, skipping...\n",
      "User : 1774\n",
      "User : 1775\n",
      "User : 1778\n",
      "User : 1793\n",
      "User : 1797\n",
      "Not Enough Data, skipping...\n",
      "User : 1799\n",
      "User : 1802\n",
      "Not Enough Data, skipping...\n",
      "User : 1809\n",
      "User : 1813\n",
      "Not Enough Data, skipping...\n",
      "User : 1814\n",
      "Not Enough Data, skipping...\n",
      "Finished predicting in 106.66662192344666 seconds\n",
      "Users without enough data : ['1097', '1205', '1247', '1269', '1276', '1277', '1280', '1480', '1491', '1511', '1518', '1531', '1554', '1679', '1683', '1696', '1723', '1724', '1726', '1745', '1750', '1757', '1761', '1763', '1797', '1802', '1813', '1814']\n"
     ]
    }
   ],
   "source": [
    "#experiment setup\n",
    "wisdm.set_data(version=\"1\", make_compatible=True)\n",
    "impersonal_df = wisdm.remove_all_nan(wisdm.data_df)\n",
    "impersonal_labels = np.array([t.decode(\"utf-8\") for t in impersonal_df['class'].as_matrix()])\n",
    "impersonal_features = impersonal_df.as_matrix(columns=[impersonal_df.columns[1:-1]])\n",
    "impersonal_scaler = StandardScaler().fit(impersonal_features)\n",
    "scaled_train_X = impersonal_scaler.transform(impersonal_features)\n",
    "impersonal_clf = wisdm.weka_RF()\n",
    "impersonal_clf.set_params(n_estimators=n_trees, n_jobs=n_cores)\n",
    "\n",
    "start=time.time()\n",
    "print(\"Training...\")\n",
    "impersonal_clf.fit(scaled_train_X, impersonal_labels)\n",
    "finished_training = time.time()\n",
    "print(\"Finished Training in %s seconds\" % (finished_training - start))\n",
    "wisdm.set_data(version=\"2\", make_compatible=True)\n",
    "result_rows = []\n",
    "\n",
    "number_of_personal_samples = 10\n",
    "ignored_users = []\n",
    "print(\"predicting...\")\n",
    "\n",
    "for user_id in wisdm.user_ids:\n",
    "    print(\"User : %s\" % user_id)\n",
    "    user_df = wisdm.data_df[wisdm.data_df['user'] == user_id]\n",
    "    \n",
    "    if len(user_df) < 40:\n",
    "        print(\"Not Enough Data, skipping...\")\n",
    "        ignored_users.append(user_id)\n",
    "        continue\n",
    "    \n",
    "    personal_labels = np.array([t.decode(\"utf-8\") for t in user_df['class'].as_matrix()])\n",
    "    personal_features = user_df.as_matrix(columns=[user_df.columns[1:-1]])\n",
    "    \n",
    "    scaled_personal_features = impersonal_scaler.transform(personal_features)\n",
    "    \n",
    "    impersonal_probabilities = impersonal_clf.predict_proba(scaled_personal_features)\n",
    "    impersonal_predictions = impersonal_clf.predict(scaled_personal_features)\n",
    "    \n",
    "    # get ranking\n",
    "    confidence_ranking = np.argsort(np.max(impersonal_probabilities, axis=1))\n",
    "    \n",
    "    ranked_predictions = impersonal_predictions[confidence_ranking]\n",
    "    ranked_truth = personal_labels[confidence_ranking]\n",
    "    \n",
    "    result_row = {\"user_id\" : user_id,\n",
    "                  \"top30\" : accuracy_score(ranked_truth[-30:], ranked_predictions[-30:]),\n",
    "                  \"bottom30\" : accuracy_score(ranked_truth[:30], ranked_predictions[:30]),\n",
    "                  \"overall\" : accuracy_score(personal_labels, impersonal_predictions)}\n",
    "    result_rows.append(result_row)\n",
    "    \n",
    "finished_predicting = time.time()\n",
    "print(\"Finished predicting in %s seconds\" % (finished_predicting - finished_training))\n",
    "print(\"Users without enough data : %s\" % ignored_users)\n",
    "\n",
    "results_df_exp2 = pd.DataFrame(result_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bottom30</th>\n",
       "      <th>overall</th>\n",
       "      <th>top30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.188462</td>\n",
       "      <td>0.387026</td>\n",
       "      <td>0.592308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.269311</td>\n",
       "      <td>0.307927</td>\n",
       "      <td>0.395790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059854</td>\n",
       "      <td>0.141667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446399</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.620896</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bottom30    overall      top30\n",
       "count  26.000000  26.000000  26.000000\n",
       "mean    0.188462   0.387026   0.592308\n",
       "std     0.269311   0.307927   0.395790\n",
       "min     0.000000   0.000000   0.000000\n",
       "25%     0.000000   0.059854   0.141667\n",
       "50%     0.000000   0.446399   0.733333\n",
       "75%     0.300000   0.620896   0.958333\n",
       "max     1.000000   1.000000   1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_exp2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick check on temporal signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(user_amounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_amounts = []\n",
    "\n",
    "for user_id in wisdm.user_ids:\n",
    "    if user_id not in users_over_longest_time:\n",
    "        user_df = wisdm.data_df[wisdm.data_df['user'] == user_id]\n",
    "        user_amounts.append(len(user_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(user_amounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_pickle('./datasets/WISDM_v2/all_raw_data.dataframe.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "study_user_ids = wisdm.data_df['user'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_study_df = raw_df[raw_df['user'].isin(study_user_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timespans = []\n",
    "\n",
    "for user_id in study_user_ids:\n",
    "    times = raw_study_df[raw_study_df['user'] == user_id]['timestamp']\n",
    "    first = times.min()\n",
    "    last = times.max()\n",
    "    span = last - first\n",
    "    timespans.append(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_rows = []\n",
    "\n",
    "for ind, user_id in enumerate(study_user_ids):\n",
    "    user_results_df = results_df_exp1_10[results_df_exp1_10['user_id'] == user_id]\n",
    "    timespan = timespans[ind]\n",
    "    \n",
    "    personal_acc = user_df['personal'].mean()\n",
    "    impersonal_acc = user_df['impersonal'].mean()\n",
    "    hybrid_acc = user_df['hybrid'].mean()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users with day1 to later ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_to_late_ratio = [1.1685393258426966,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 4.148148148148148,\n",
    " 1.0,\n",
    " 0.33739837398373984,\n",
    " 2.0,\n",
    " 1.0,\n",
    " 1.121212121212121,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.13636363636363635,\n",
    " 1.0,\n",
    " 0.10294117647058823,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.8666666666666667,\n",
    " 1.0,\n",
    " 0.0622876557191393,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.184375,\n",
    " 2.025,\n",
    " 0.5714285714285714,\n",
    " 1.0,\n",
    " 3.8947368421052633,\n",
    " 1.0,\n",
    " 0.43661971830985913,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 5.071428571428571,\n",
    " 0.304635761589404,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.5119047619047619,\n",
    " 1.0,\n",
    " 1.0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = ['194',\n",
    " '998',\n",
    " '1104',\n",
    " '1117',\n",
    " '1205',\n",
    " '1238',\n",
    " '1246',\n",
    " '1247',\n",
    " '1253',\n",
    " '1269',\n",
    " '1274',\n",
    " '1277',\n",
    " '1280',\n",
    " '1319',\n",
    " '1320',\n",
    " '1477',\n",
    " '1480',\n",
    " '1491',\n",
    " '1511',\n",
    " '1512',\n",
    " '1518',\n",
    " '1531',\n",
    " '1554',\n",
    " '1559',\n",
    " '1603',\n",
    " '1676',\n",
    " '1679',\n",
    " '1683',\n",
    " '1696',\n",
    " '1703',\n",
    " '1707',\n",
    " '1724',\n",
    " '1742',\n",
    " '1745',\n",
    " '1750',\n",
    " '1757',\n",
    " '1758',\n",
    " '1759',\n",
    " '1761',\n",
    " '1763',\n",
    " '1774',\n",
    " '1775',\n",
    " '1778',\n",
    " '1793',\n",
    " '1797',\n",
    " '1799',\n",
    " '1802']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "personal_means = []\n",
    "impersonal_means = []\n",
    "hybrid_means = []\n",
    "\n",
    "users_to_plot = []\n",
    "ratio = []\n",
    "for ind, user_id in enumerate(users):\n",
    "    user_df = results_df_exp1_10[results_df_exp1_10['user_id'] == user_id]\n",
    "    if len(user_df) > 0:\n",
    "        personal_means.append(user_df['personal'].mean())\n",
    "        impersonal_means.append(user_df['impersonal'].mean())\n",
    "        hybrid_means.append(user_df['hybrid'].mean())\n",
    "        users_to_plot.append(user_id)\n",
    "        ratio.append(early_to_late_ratio[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(personal_means, ratio)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(personal_means, ratio)\n",
    "\n",
    "line = slope*np.array(personal_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=personal_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "personal_trace = go.Scatter(x=personal_means,\n",
    "                            y=ratio,\n",
    "                            mode=\"markers\")\n",
    "data=[personal_trace, line_trace]\n",
    "\n",
    "title = 'Personal Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='Ratio of labels < 1 hour to labels > 1 hour'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(impersonal_means, ratio)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(impersonal_means, ratio)\n",
    "\n",
    "line = slope*np.array(impersonal_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=impersonal_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "impersonal_trace = go.Scatter(x=impersonal_means,\n",
    "                            y=ratio,\n",
    "                            mode=\"markers\")\n",
    "data=[impersonal_trace, line_trace]\n",
    "\n",
    "title = 'impersonal Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='Ratio of labels < 1 hour to labels > 1 hour'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(hybrid_means, ratio)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(hybrid_means, ratio)\n",
    "\n",
    "line = slope*np.array(hybrid_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=hybrid_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "hybrid_trace = go.Scatter(x=hybrid_means,\n",
    "                            y=ratio,\n",
    "                            mode=\"markers\")\n",
    "data=[hybrid_trace, line_trace]\n",
    "\n",
    "title = 'hybrid Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='Ratio of labels < 1 hour to labels > 1 hour'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_deltas = [23.221944444444443,\n",
    " 0.61361111111111111,\n",
    " 0.44083333333333335,\n",
    " 23.722777777777779,\n",
    " 0.024722222222222222,\n",
    " 23.2575,\n",
    " 9.8166666666666664,\n",
    " 0.063888888888888884,\n",
    " 15.842499999999999,\n",
    " 0.0025000000000000001,\n",
    " 0.065833333333333327,\n",
    " 4.402222222222222,\n",
    " 0.033055555555555553,\n",
    " 20.708055555555557,\n",
    " 0.89583333333333337,\n",
    " 0.20694444444444443,\n",
    " 0.046944444444444441,\n",
    " 0.03833333333333333,\n",
    " 0.01638888888888889,\n",
    " 0.84916666666666663,\n",
    " 0.073888888888888893,\n",
    " 0.30055555555555558,\n",
    " 1.2597222222222222,\n",
    " 0.16972222222222222,\n",
    " 23.955555555555556,\n",
    " 0.55583333333333329,\n",
    " 0.01361111111111111,\n",
    " 0.046944444444444441,\n",
    " 2.3138888888888891,\n",
    " 5.2169444444444446,\n",
    " 4.7552777777777777,\n",
    " 0.16805555555555557,\n",
    " 16.563055555555554,\n",
    " 0.030277777777777778,\n",
    " 15.786666666666667,\n",
    " 0.0080555555555555554,\n",
    " 0.23833333333333334,\n",
    " 0.50916666666666666,\n",
    " 0.14444444444444443,\n",
    " 0.05527777777777778,\n",
    " 22.757222222222222,\n",
    " 2.1077777777777778,\n",
    " 0.35249999999999998,\n",
    " 0.28083333333333332,\n",
    " 5.371666666666667,\n",
    " 0.57666666666666666,\n",
    " 0.18361111111111111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_deltas_users = ['194',\n",
    " '998',\n",
    " '1104',\n",
    " '1117',\n",
    " '1205',\n",
    " '1238',\n",
    " '1246',\n",
    " '1247',\n",
    " '1253',\n",
    " '1269',\n",
    " '1274',\n",
    " '1277',\n",
    " '1280',\n",
    " '1319',\n",
    " '1320',\n",
    " '1477',\n",
    " '1480',\n",
    " '1491',\n",
    " '1511',\n",
    " '1512',\n",
    " '1518',\n",
    " '1531',\n",
    " '1554',\n",
    " '1559',\n",
    " '1603',\n",
    " '1676',\n",
    " '1679',\n",
    " '1683',\n",
    " '1696',\n",
    " '1703',\n",
    " '1707',\n",
    " '1724',\n",
    " '1742',\n",
    " '1745',\n",
    " '1750',\n",
    " '1757',\n",
    " '1758',\n",
    " '1759',\n",
    " '1761',\n",
    " '1763',\n",
    " '1774',\n",
    " '1775',\n",
    " '1778',\n",
    " '1793',\n",
    " '1797',\n",
    " '1799',\n",
    " '1802']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "personal_means = []\n",
    "impersonal_means = []\n",
    "hybrid_means = []\n",
    "\n",
    "users_to_plot = []\n",
    "tds = []\n",
    "for ind, user_id in enumerate(time_deltas_users):\n",
    "    user_df = results_df_exp1_10[results_df_exp1_10['user_id'] == user_id]\n",
    "    if len(user_df) > 0:\n",
    "        personal_means.append(user_df['personal'].mean())\n",
    "        impersonal_means.append(user_df['impersonal'].mean())\n",
    "        hybrid_means.append(user_df['hybrid'].mean())\n",
    "        users_to_plot.append(user_id)\n",
    "        tds.append(time_deltas[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(personal_means, tds)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(personal_means, tds)\n",
    "\n",
    "line = slope*np.array(personal_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=personal_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "personal_trace = go.Scatter(x=personal_means,\n",
    "                            y=tds,\n",
    "                            mode=\"markers\")\n",
    "data=[personal_trace, line_trace]\n",
    "\n",
    "title = 'personal Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='Time Deltas'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(impersonal_means, tds)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(impersonal_means, tds)\n",
    "\n",
    "line = slope*np.array(impersonal_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=impersonal_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "impersonal_trace = go.Scatter(x=impersonal_means,\n",
    "                            y=tds,\n",
    "                            mode=\"markers\")\n",
    "data=[impersonal_trace, line_trace]\n",
    "\n",
    "title = 'impersonal Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='Time Deltas'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(hybrid_means, tds)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(hybrid_means, tds)\n",
    "\n",
    "line = slope*np.array(hybrid_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=hybrid_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "hybrid_trace = go.Scatter(x=hybrid_means,\n",
    "                            y=tds,\n",
    "                            mode=\"markers\")\n",
    "data=[hybrid_trace, line_trace]\n",
    "\n",
    "title = 'hybrid Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='Time Deltas'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with 30 personal samples for personal and hybrid models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "personal_means = []\n",
    "impersonal_means = []\n",
    "hybrid_means = []\n",
    "\n",
    "users_to_plot = []\n",
    "ratio = []\n",
    "for ind, user_id in enumerate(users):\n",
    "    user_df = results_df_exp1_30[results_df_exp1_30['user_id'] == user_id]\n",
    "    if len(user_df) > 0:\n",
    "        personal_means.append(user_df['personal'].mean())\n",
    "        impersonal_means.append(user_df['impersonal'].mean())\n",
    "        hybrid_means.append(user_df['hybrid'].mean())\n",
    "        users_to_plot.append(user_id)\n",
    "        ratio.append(early_to_late_ratio[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(personal_means, (1. / np.array(ratio)))\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(personal_means, (1. / np.array(ratio)))\n",
    "\n",
    "line = slope*np.array(personal_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=personal_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "personal_trace = go.Scatter(x=personal_means,\n",
    "                            y=(1. / np.array(ratio)),\n",
    "                            mode=\"markers\")\n",
    "data=[personal_trace, line_trace]\n",
    "\n",
    "title = 'personal Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='(1. / np.array(ratio)) of labels < 1 hour to labels > 1 hour'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(impersonal_means, (1. / np.array(ratio)))\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(impersonal_means, (1. / np.array(ratio)))\n",
    "\n",
    "line = slope*np.array(impersonal_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=impersonal_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "impersonal_trace = go.Scatter(x=impersonal_means,\n",
    "                            y=(1. / np.array(ratio)),\n",
    "                            mode=\"markers\")\n",
    "data=[impersonal_trace, line_trace]\n",
    "\n",
    "title = 'impersonal Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='(1. / np.array(ratio)) of labels < 1 hour to labels > 1 hour'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(hybrid_means, (1. / np.array(ratio)))\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(hybrid_means, (1. / np.array(ratio)))\n",
    "\n",
    "line = slope*np.array(hybrid_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=hybrid_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "hybrid_trace = go.Scatter(x=hybrid_means,\n",
    "                            y=(1. / np.array(ratio)),\n",
    "                            mode=\"markers\")\n",
    "data=[hybrid_trace, line_trace]\n",
    "\n",
    "title = 'hybrid Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='(1. / np.array(ratio)) of labels < 1 hour to labels > 1 hour'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(personal_means, tds)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(personal_means, tds)\n",
    "\n",
    "line = slope*np.array(personal_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=personal_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "personal_trace = go.Scatter(x=personal_means,\n",
    "                            y=tds,\n",
    "                            mode=\"markers\")\n",
    "data=[personal_trace, line_trace]\n",
    "\n",
    "title = 'personal Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='Time Deltas'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(impersonal_means, tds)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(impersonal_means, tds)\n",
    "\n",
    "line = slope*np.array(impersonal_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=impersonal_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "impersonal_trace = go.Scatter(x=impersonal_means,\n",
    "                            y=tds,\n",
    "                            mode=\"markers\")\n",
    "data=[impersonal_trace, line_trace]\n",
    "\n",
    "title = 'impersonal Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='Time Deltas'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau, p = stats.kendalltau(hybrid_means, tds)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(hybrid_means, tds)\n",
    "\n",
    "line = slope*np.array(hybrid_means)+intercept\n",
    "\n",
    "line_trace = go.Scatter(x=hybrid_means,\n",
    "                        y=line,\n",
    "                        mode='lines',\n",
    "                        name='Fit')\n",
    "\n",
    "hybrid_trace = go.Scatter(x=hybrid_means,\n",
    "                            y=tds,\n",
    "                            mode=\"markers\")\n",
    "data=[hybrid_trace, line_trace]\n",
    "\n",
    "title = 'hybrid Model : tau=%.5f, p=%.5f' % (tau, p)\n",
    "layout=go.Layout(yaxis=dict(title='Time Deltas'),\n",
    "                 xaxis=dict(title='Accuracy', range=[0,1]),\n",
    "                 title=title)\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
