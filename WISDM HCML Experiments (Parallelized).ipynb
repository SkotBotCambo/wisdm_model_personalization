{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo :\n",
    "\n",
    "* ~~consolidate code from notebook into WISDM helper methods file~~\n",
    "* rewrite kfolds process so that we have more precise control over the size of a fold (as oppose to just the number of folds)\n",
    "* run experiment that directly compares model using ALL general data + active data to model using ONLY general data from nearest cluster + active data\n",
    "* analyze/visualize clusters (is there a better algorithm? is there a better k for the k-means?) \n",
    "* perhaps compare with using the WORST cluster, or using ONLY the personal data\n",
    "    * for each size of active data\n",
    "        * for each algorithm (also ensemble algorithm?)\n",
    "            * personal only\n",
    "            * universal only\n",
    "            * personal + ALL universal\n",
    "            * personal + best cluster universal\n",
    "            * personal + worst cluster universal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wisdm import wisdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wisdm.WISDM_DIR = wisdm.wisdm_v2_dataset_path\n",
    "wisdm.WISDM_TRANSFORMED = wisdm.wisdm_transformed_v2\n",
    "\n",
    "wisdm.set_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Universal Impersonal Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for 194: 0.482\n",
      "Score for 998: 0.637\n",
      "Score for 1097: 0.306\n",
      "Score for 1104: 0.619\n",
      "Score for 1117: 0.269\n",
      "Score for 1205: 1.000\n",
      "Score for 1238: 0.670\n",
      "Score for 1246: 1.000\n",
      "Score for 1247: 0.000\n",
      "Score for 1253: 0.833\n",
      "Score for 1269: 0.000\n",
      "Score for 1274: 1.000\n",
      "Score for 1276: 0.000\n",
      "Score for 1277: 1.000\n",
      "Score for 1280: 0.000\n",
      "Score for 1319: 0.692\n",
      "Score for 1320: 0.352\n",
      "Score for 1477: 0.086\n",
      "Score for 1480: 0.000\n",
      "Score for 1491: 0.000\n",
      "Score for 1511: 1.000\n",
      "Score for 1512: 1.000\n",
      "Score for 1518: 1.000\n",
      "Score for 1531: 1.000\n",
      "Score for 1554: 0.917\n",
      "Score for 1559: 0.830\n",
      "Score for 1603: 0.480\n",
      "Score for 1676: 0.291\n",
      "Score for 1679: 0.000\n",
      "Score for 1683: 1.000\n",
      "Score for 1696: 1.000\n",
      "Score for 1703: 0.812\n",
      "Score for 1707: 0.135\n",
      "Score for 1723: 0.333\n",
      "Score for 1724: 0.000\n",
      "Score for 1726: 0.667\n",
      "Score for 1742: 0.284\n",
      "Score for 1745: 0.000\n",
      "Score for 1750: 0.167\n",
      "Score for 1757: 1.000\n",
      "Score for 1758: 0.769\n",
      "Score for 1759: 0.724\n",
      "Score for 1761: 0.455\n",
      "Score for 1763: 0.000\n",
      "Score for 1774: 0.724\n",
      "Score for 1775: 0.339\n",
      "Score for 1778: 0.375\n",
      "Score for 1793: 0.575\n",
      "Score for 1797: 0.444\n",
      "Score for 1799: 0.201\n",
      "Score for 1802: 0.667\n",
      "Score for 1809: 0.149\n",
      "Score for 1813: 1.000\n",
      "Score for 1814: 1.000\n",
      "RF results : M=0.52380, SD=0.37142\n"
     ]
    }
   ],
   "source": [
    "rf_results = []\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for user_id in wisdm.user_ids:\n",
    "        test_set = wisdm.get_user_set(user_id)\n",
    "        test_set = wisdm.remove_all_nan(test_set)\n",
    "\n",
    "        test_labels = np.array([t.decode(\"utf-8\") for t in test_set['class'].as_matrix()])\n",
    "        test_features = test_set.as_matrix(columns=[test_set.columns[1:-1]])\n",
    "\n",
    "        #print(\"%s labels, %s features\" % (len(test_labels), len(test_features)))\n",
    "        # training features & labels\n",
    "        training_set = wisdm.data_df[wisdm.data_df['user'] != user_id]\n",
    "        training_set = wisdm.remove_all_nan(training_set)\n",
    "        training_labels = np.array([t.decode(\"utf-8\") for t in training_set['class'].as_matrix()])\n",
    "        training_features = training_set.as_matrix(columns=[test_set.columns[1:-1]])\n",
    "\n",
    "        # normalize features\n",
    "        scaler = StandardScaler().fit(training_features)\n",
    "        scaled_train_x = scaler.transform(training_features)\n",
    "        scaled_test_x = scaler.transform(test_features)\n",
    "\n",
    "        clf = wisdm.weka_RF()\n",
    "        clf.fit(scaled_train_x, training_labels)\n",
    "        predictions = clf.predict(scaled_test_x)\n",
    "\n",
    "        score = accuracy_score(test_labels, predictions)\n",
    "        print(\"Score for %s: %.3f\" % (user_id, score))\n",
    "        rf_results.append(score)\n",
    "\n",
    "print(\"RF results : M=%.5f, SD=%.5f\" % (np.mean(rf_results), np.std(rf_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took about 23.12292218208313 seconds\n"
     ]
    }
   ],
   "source": [
    "finish = time.time()\n",
    "print(\"Took about %s seconds\" % (finish - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelized Universal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ipp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview = c[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter_result = dview.scatter(\"user_ids\", wisdm.user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['194', '998'], dtype=object),\n",
       " array(['1097', '1104'], dtype=object),\n",
       " array(['1117', '1205'], dtype=object),\n",
       " array(['1238', '1246'], dtype=object),\n",
       " array(['1247', '1253'], dtype=object),\n",
       " array(['1269', '1274'], dtype=object),\n",
       " array(['1276', '1277'], dtype=object),\n",
       " array(['1280', '1319'], dtype=object),\n",
       " array(['1320', '1477'], dtype=object),\n",
       " array(['1480', '1491'], dtype=object),\n",
       " array(['1511', '1512'], dtype=object),\n",
       " array(['1518', '1531'], dtype=object),\n",
       " array(['1554', '1559'], dtype=object),\n",
       " array(['1603', '1676'], dtype=object),\n",
       " array(['1679', '1683'], dtype=object),\n",
       " array(['1696', '1703'], dtype=object),\n",
       " array(['1707', '1723'], dtype=object),\n",
       " array(['1724', '1726'], dtype=object),\n",
       " array(['1742', '1745'], dtype=object),\n",
       " array(['1750', '1757'], dtype=object),\n",
       " array(['1758', '1759'], dtype=object),\n",
       " array(['1761', '1763'], dtype=object),\n",
       " array(['1774'], dtype=object),\n",
       " array(['1775'], dtype=object),\n",
       " array(['1778'], dtype=object),\n",
       " array(['1793'], dtype=object),\n",
       " array(['1797'], dtype=object),\n",
       " array(['1799'], dtype=object),\n",
       " array(['1802'], dtype=object),\n",
       " array(['1809'], dtype=object),\n",
       " array(['1813'], dtype=object),\n",
       " array(['1814'], dtype=object)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview['user_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_wisdm_helpers_path():\n",
    "    import sys\n",
    "    sys.path.append(\"/home/sac086/hcml_chapter/wisdm_model_personalization/notebooks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: add_wisdm_helpers_path>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.apply_async(add_wisdm_helpers_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "import warnings\n",
    "import os\n",
    "from wisdm import wisdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing warnings on engine(s)\n",
      "importing os on engine(s)\n",
      "importing wisdm from wisdm on engine(s)\n",
      "importing numpy on engine(s)\n",
      "importing pandas on engine(s)\n",
      "importing accuracy_score from sklearn.metrics on engine(s)\n",
      "importing StandardScaler from sklearn.preprocessing on engine(s)\n",
      "importing StratifiedKFold,StratifiedShuffleSplit from sklearn.model_selection on engine(s)\n",
      "importing KMeans from sklearn.cluster on engine(s)\n",
      "importing mode from scipy.stats on engine(s)\n"
     ]
    }
   ],
   "source": [
    "with dview.sync_imports():\n",
    "    import warnings\n",
    "    import os\n",
    "    from wisdm import wisdm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "    from sklearn.cluster import KMeans\n",
    "    from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview.block=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    wisdm_1_dir = \"/home/sac086/wisdm_model_personalization/datasets/WISDM_v1/\"\n",
    "    wisdm_1_transformed_data  = \"WISDM_ar_v1.1_transformed_FIXED.arff\"\n",
    "    wisdm_2_dir = \"/home/sac086/wisdm_model_personalization/datasets/WISDM_v2/\"\n",
    "    wisdm_2_transformed_data = \"WISDM_at_v2.0_transformed_FIXED.arff\"\n",
    "    \n",
    "    wisdm.WISDM_DIR = wisdm_2_dir\n",
    "    wisdm.WISDM_TRANSFORMED = wisdm_2_transformed_data\n",
    "    \n",
    "    wisdm.set_data()\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.apply(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation with exact number of data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Attributes : \n",
    "* amount of training set from individual end user\n",
    "* amount of training set from impersonal data (other users)\n",
    "    * \"ALL\" all other data\n",
    "    * \"closest cluster\" only data from the closest cluster\n",
    "    * \"furthest cluster\" only data from the furthest cluster\n",
    "    * \"All - furthest cluster\" all other data EXCEPT data from furthest cluster\n",
    "* test user id\n",
    "* algorithm\n",
    "* algorithm parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "def personal_model(active_features, active_labels, test_features, test_labels):\n",
    "    scaler = StandardScaler().fit(active_features)\n",
    "    scaled_train_x = scaler.transform(active_features)\n",
    "    scaled_test_x = scaler.transform(test_features)\n",
    "\n",
    "    rfc_clf = wisdm.weka_RF()\n",
    "    rfc_clf.fit(scaled_train_x, active_labels)\n",
    "    predictions = rfc_clf.predict(scaled_test_x)\n",
    "    score = accuracy_score(test_labels, predictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "def universal_model(universal_features, universal_labels, test_features, test_labels):\n",
    "    scaler = StandardScaler().fit(universal_features)\n",
    "    scaled_train_x = scaler.transform(universal_features)\n",
    "    scaled_test_x = scaler.transform(test_features)\n",
    "\n",
    "    rfc_clf = wisdm.weka_RF()\n",
    "    rfc_clf.fit(scaled_train_x, universal_labels)\n",
    "    predictions = rfc_clf.predict(scaled_test_x)\n",
    "    score = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "def universal_plus_personal_model(personal_features, personal_labels,\n",
    "                                  universal_features, universal_labels,\n",
    "                                  test_features, test_labels):\n",
    "    personal_plus_universal_features = np.vstack((personal_features, universal_features))\n",
    "    personal_plus_universal_labels = np.hstack((personal_labels, universal_labels))\n",
    "\n",
    "    scaler = StandardScaler().fit(personal_plus_universal_features)\n",
    "    scaled_train_x = scaler.transform(personal_plus_universal_features)\n",
    "    scaled_test_x = scaler.transform(test_features)\n",
    "\n",
    "    rfc_clf = wisdm.weka_RF()\n",
    "\n",
    "    rfc_clf.fit(scaled_train_x, personal_plus_universal_labels)\n",
    "    predictions = rfc_clf.predict(scaled_test_x)\n",
    "    score = accuracy_score(test_labels, predictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "def cluster_plus_personal_model(personal_features, personal_labels,\n",
    "                                  universal_features, universal_labels,\n",
    "                                  test_features, test_labels, KM, clusters):\n",
    "    cluster_predictions = KM.predict(personal_features)\n",
    "    closest_cluster = mode(cluster_predictions).mode[0]\n",
    "\n",
    "    cluster_data_indeces = [i for i in range(len(clusters)) if clusters[i] == closest_cluster]\n",
    "    cluster_features = universal_features[cluster_data_indeces]\n",
    "    cluster_labels = universal_labels[cluster_data_indeces]\n",
    "\n",
    "    training_features = np.vstack((personal_features, cluster_features))\n",
    "    training_labels = np.hstack((personal_labels, cluster_labels))\n",
    "\n",
    "    scaler = StandardScaler().fit(training_features)\n",
    "    scaled_train_x = scaler.transform(training_features)\n",
    "    scaled_test_x = scaler.transform(test_features)\n",
    "\n",
    "    rfc_clf = wisdm.weka_RF()\n",
    "\n",
    "    rfc_clf.fit(scaled_train_x, training_labels)\n",
    "    predictions = rfc_clf.predict(scaled_test_x)\n",
    "    score = accuracy_score(test_labels, predictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "training_sizes = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "def all_models():\n",
    "    scores = []\n",
    "    err = None\n",
    "    training_sizes = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for ind, user_id in enumerate(user_ids):\n",
    "            user_scores_df = []\n",
    "            print(\"Running user #%s: %s\" % (ind, user_id))\n",
    "            personal_set = wisdm.get_user_set(user_id)\n",
    "            personal_set = wisdm.remove_all_nan(personal_set)\n",
    "\n",
    "            personal_labels = np.array([t.decode(\"utf-8\") for t in personal_set['class'].as_matrix()])\n",
    "            personal_features = personal_set.as_matrix(columns=[personal_set.columns[1:-1]])\n",
    "\n",
    "            # What is the distribution of labels for this participant?\n",
    "            personal_labels_distribution = Counter(personal_labels)\n",
    "            print(\"\\tHas %s labels : \" % len(personal_labels))\n",
    "            for label_key, number in personal_labels_distribution.items():\n",
    "                print(\"\\t\\t%s:%s\" % (label_key, number))\n",
    "            print(\"\\n\")\n",
    "            # training features & labels\n",
    "            universal_set = wisdm.data_df[wisdm.data_df['user'] != user_id]\n",
    "            universal_set = wisdm.remove_all_nan(universal_set)\n",
    "            universal_labels = np.array([t.decode(\"utf-8\") for t in universal_set['class'].as_matrix()])\n",
    "            universal_features = universal_set.as_matrix(columns=[universal_set.columns[1:-1]])\n",
    "\n",
    "            # get k-means clusters\n",
    "            number_of_clusters = 4 # the higher this number is, the smaller we should expect each cluster to be\n",
    "\n",
    "            KM = KMeans(n_clusters=number_of_clusters)\n",
    "            clusters = KM.fit_predict(universal_features)\n",
    "            k = 10\n",
    "\n",
    "            skf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "            k_run = 0\n",
    "            try:\n",
    "                for active_index, test_index in skf.split(personal_features, personal_labels):\n",
    "                    print(\"\\tRunning Fold #%s\\n\" % k_run)\n",
    "                    # data set available for active labeling from the individual\n",
    "                    all_active_features = personal_features[active_index]\n",
    "                    all_active_labels = personal_labels[active_index]\n",
    "\n",
    "\n",
    "                    # held out test set from individual\n",
    "                    test_features = personal_features[test_index]\n",
    "                    test_labels = personal_labels[test_index]\n",
    "\n",
    "                    # iterate through size of training data\n",
    "                    for training_size in training_sizes:\n",
    "                        # initialize score holders\n",
    "                        personal_model_scores = []\n",
    "                        universal_model_scores = []\n",
    "                        personal_plus_all_scores = []\n",
    "                        personal_plus_cluster_scores = []\n",
    "\n",
    "                        # run universal model\n",
    "                        universal_model_score = universal_model(universal_features, universal_labels,\n",
    "                                                                test_features, test_labels)\n",
    "                        universal_model_scores.append(universal_model_score)\n",
    "\n",
    "                        sss = StratifiedShuffleSplit(n_splits=5, train_size=training_size)\n",
    "\n",
    "                        splits = sss.split(all_active_features, all_active_labels)\n",
    "\n",
    "                        try:\n",
    "                            for split_num, split_tup in enumerate(splits):\n",
    "                                sampled_active_index, __ = split_tup\n",
    "                                sampled_active_features = personal_features[sampled_active_index]\n",
    "                                sampled_active_labels = personal_labels[sampled_active_index]\n",
    "\n",
    "                                # run personal model\n",
    "                                personal_score = personal_model(sampled_active_features, sampled_active_labels, test_features, test_labels)\n",
    "                                personal_model_scores.append(personal_score)\n",
    "\n",
    "                                # run personal + universal\n",
    "                                personal_plus_all_score = universal_plus_personal_model(sampled_active_features, sampled_active_labels,\n",
    "                                                                                        universal_features, universal_labels,\n",
    "                                                                                        test_features, test_labels)\n",
    "                                personal_plus_all_scores.append(personal_plus_all_score)\n",
    "\n",
    "                                # run personal + cluster\n",
    "                                personal_plus_cluster_score = cluster_plus_personal_model(sampled_active_features, sampled_active_labels,\n",
    "                                                                                        universal_features, universal_labels,\n",
    "                                                                                        test_features, test_labels, KM, clusters)\n",
    "                                personal_plus_cluster_scores.append(personal_plus_cluster_score)\n",
    "                        except ValueError as ve:\n",
    "                            print(\"Error with training size while trying to split personal data\")\n",
    "                            print(\"Message : %s\" % ve.args[0])\n",
    "                            err = ve\n",
    "                            if \"Reduce test_size and/or train_size\" in ve.args[0]:\n",
    "                                print(\"continuing...\")\n",
    "                                continue\n",
    "                            elif \"should be smaller than the number of samples\" in ve.args[0]:\n",
    "                                print(\"continuing...\")\n",
    "                                continue\n",
    "                            elif \"The least populated class in y has only 1 member\" in ve.args[0]:\n",
    "                                print(\"continuing...\")\n",
    "                                continue\n",
    "                            else:\n",
    "                                raise(ve)\n",
    "\n",
    "                        row = {\"test user\" : user_id,\n",
    "                               \"k-run\" : k_run,\n",
    "                           \"classifier\" : \"RF with Wiki Parameters\",\n",
    "                           \"personal training data\" : training_size,\n",
    "                           \"personal score Mean\" : np.mean(personal_model_scores),\n",
    "                           \"personal score STD\" : np.std(personal_model_scores),\n",
    "                           \"impersonal score Mean\" : np.mean(universal_model_scores),\n",
    "                           \"impersonal score STD\" : np.std(universal_model_scores),\n",
    "                           \"personal + impersonal score Mean\" : np.mean(personal_plus_all_scores),\n",
    "                           \"personal + impersonal score STD\" : np.std(personal_plus_all_scores),\n",
    "                           \"personal + cluster score Mean\" : np.mean(personal_plus_cluster_scores),\n",
    "                           \"personal + cluster score STD\" : np.std(personal_plus_cluster_scores)\n",
    "                           }\n",
    "                        print(\"\\tamount of personal data : %s row\" % training_size)\n",
    "                        print(\"\\tpersonal model score : M=%.3f, SD=%.3f\" % (row[\"personal score Mean\"], row[\"personal score STD\"]))\n",
    "                        print(\"\\tuniversal model score : M=%.3f, SD=%.3f\" % (row[\"impersonal score Mean\"], row[\"impersonal score STD\"]))\n",
    "                        print(\"\\tpersonal + ALL universal : M=%.3f, SD=%.3f\" % (row[\"personal + impersonal score Mean\"], row[\"personal + impersonal score STD\"]))\n",
    "                        print(\"\\tpersonal + CLUSTER universal : M=%.3f, SD=%.3f\" % (row[\"personal + cluster score Mean\"], row[\"personal + cluster score STD\"]))\n",
    "                        print(\"\\n\")\n",
    "                        scores.append(row)\n",
    "                        user_scores_df.append(row)\n",
    "                    k_run += 1\n",
    "            except ValueError as ve:\n",
    "                if \"Cannot have number of splits n_splits\" in ve.args[0]:\n",
    "                    print(\"Skipping this k-fold because there is not enough data...\")\n",
    "                    continue\n",
    "                else:\n",
    "                    raise ve\n",
    "            user_scores_df = pd.DataFrame(user_scores_df)\n",
    "            user_scores_df.to_pickle(\"/home/sac086/wisdm_model_personalization/results/experiment_08-21_v2_dataset/\"+user_id+\".pickle\")\n",
    "\n",
    "    scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview.block = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = dview.execute(\"all_models()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished all models in 1566.3238887786865 seconds\n"
     ]
    }
   ],
   "source": [
    "finish = time.time()\n",
    "print(\"Finished all models in %s seconds\" % (finish - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Paralellizing to run on WISDM_2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
